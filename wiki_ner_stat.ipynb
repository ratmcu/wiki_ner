{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wiki_ner_stat.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ratmcu/wiki_ner/blob/master/wiki_ner_stat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAQ6ZbTGqpwp",
        "colab_type": "code",
        "outputId": "0ca78e3c-fb64-4d71-f67c-26f7b330e64d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "import pandas as pd\n",
        "!pip install wget\n",
        "import wget\n",
        "import pickle\n",
        "import ast\n",
        "\n",
        "class hashabledict(dict):\n",
        "    def __hash__(self):\n",
        "        return hash(tuple(sorted(self.items())))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ1yOIZcq-Nx",
        "colab_type": "code",
        "outputId": "df6a69b5-6288-4f19-c922-d30b7720b76b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "if os.path.isfile('dataset.tar.gz'):\n",
        "    print('data set is inplace')\n",
        "else:\n",
        "    print('downloading the dataset from the git')\n",
        "    wget.download('https://github.com/ratmcu/wiki_ner/blob/master/dataset.tar.gz?raw=true')\n",
        "\n",
        "if os.path.isfile('president_list.pkl'):\n",
        "    print('url list is inplace')\n",
        "else:\n",
        "    print('downloading the url list from the git')\n",
        "    wget.download('https://github.com/ratmcu/wiki_ner/blob/master/president_list.pkl?raw=true')\n",
        "\n",
        "tar = tarfile.open(\"dataset.tar.gz\", mode='r')\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "# dir(tarfile)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data set is inplace\n",
            "url list is inplace\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2p3KKO2BeGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WikiNameEntities():\n",
        "    def __init__(self, path = './data'):\n",
        "        import random\n",
        "#         download the files or check them\n",
        "#         read all the files and load\n",
        "#         self.names = [1, 2, 3, 3, 4 ,5]\n",
        "        self.path_prefix =  path\n",
        "        self.annotation_index = 0\n",
        "        self.page_index = 0\n",
        "        self.dictionary = {'sentences': [], 'annotations': [] }\n",
        "        self.index_list  = list(0 for i in range(0, len(self.total_annotations)) \n",
        "        self.total_annotations = 0\n",
        "        \n",
        "    def load_file(self, tcountry, name, prefix=''):\n",
        "        anntn_pth = prefix + country + '/' + name + '/' + 'annotations.csv'\n",
        "        sntnce_pth = prefix + country + '/' + name + '/' + 'sentences.csv'\n",
        "        if os.path.isfile(anntn_pth) and os.path.isfile(sntnce_pth):\n",
        "            annotations = pd.read_csv(anntn_pth)\n",
        "            sentences = pd.read_csv(sntnce_pth)\n",
        "            return [annotations, sentences]\n",
        "        return None\n",
        "    \n",
        "    def chain_files(self):\n",
        "        pages = 0\n",
        "        for country in prsdnt_list:\n",
        "            for president in country['presidents']:\n",
        "                if country['country'] and president['name']:\n",
        "                    contents = self.load_file(country['country'], president['name'], self.path_prefix)\n",
        "                    if contents:\n",
        "                        \n",
        "                        self.total_annotations = self.total_annotations + len(contents[0])\n",
        "#                         annotation = contents[0]\n",
        "#                         sentences = contents[1]\n",
        "                        self.dictionary['annotations'].append((pages, contents[0]))\n",
        "                        pages = pages + 1\n",
        "                        self.dictionary['sentences'].append(contents[1])\n",
        "        print('loaded {0} pages'.format(pages))\n",
        "    \n",
        "    def random_fill_index_list(self):\n",
        "        check_list = list(0 for i in range(0, len(self.total_annotations)))\n",
        "        fill_count = 0\n",
        "        while fill_count != len(self.total_annotations):\n",
        "            index = random.randrange(0, len(self.total_annotations))\n",
        "            if check_list[index] == 0:\n",
        "                check_list[index] = 1\n",
        "                self.index_list[fill_count] = index\n",
        "                fill_count = fill_count + 1\n",
        "        \n",
        "        \n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.annotation_index = 0\n",
        "        self.page_index = 0\n",
        "        self.index_list  = list(0 for i in range(0, self.total_annotations-1))\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.done_iterating():\n",
        "            raise StopIteration\n",
        "        num = self.names[self.index]\n",
        "        self.index += 1\n",
        "        return sentence, annotation     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrDbCSY42nJX",
        "colab_type": "code",
        "outputId": "6979dfad-45ed-4f5f-d48f-d388103753ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open('president_list.pkl', 'rb') as f:\n",
        "    prsdnt_list = pickle.load(f)\n",
        "    \n",
        "path_prefix = r'dataset/politicians/'\n",
        "\n",
        "def load_file(country, name, prefix=''):\n",
        "    anntn_pth = prefix + country + '/' + name + '/' + 'annotations.csv'\n",
        "    sntnce_pth = prefix + country + '/' + name + '/' + 'sentences.csv'\n",
        "    if os.path.isfile(anntn_pth) and os.path.isfile(sntnce_pth):\n",
        "        annotations = pd.read_csv(anntn_pth)\n",
        "        sentences = pd.read_csv(sntnce_pth)\n",
        "        return [annotations, sentences]\n",
        "    return None\n",
        "\n",
        "# def rank_annotations(annotation):\n",
        "    \n",
        "number_of_annotations = 0\n",
        "max_num_annotations = 0\n",
        "max_candidate = ''\n",
        "max_annotations = pd.DataFrame()\n",
        "pages = 0\n",
        "ranks = []\n",
        "\n",
        "for country in prsdnt_list:\n",
        "    for president in country['presidents']:\n",
        "        if country['country'] and president['name']:\n",
        "            contents = load_file(country['country'], president['name'], path_prefix)\n",
        "            if contents:\n",
        "                pages = pages + 1\n",
        "                annotation = contents[0]\n",
        "                sentences = contents[1]\n",
        "                number_of_annotations = number_of_annotations + len(annotation)\n",
        "                if max_num_annotations < len(annotation):\n",
        "                    max_num_annotations = len(annotation) \n",
        "                    max_candidate = president['name']\n",
        "                    max_annotations = annotation\n",
        "print(number_of_annotations, max_num_annotations, pages)                \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14272 228 1032\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZAqIYrgO4hv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAZCqkwnz1tv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ast\n",
        "fruits = ast.literal_eval(max_annotations.iloc[3][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AyJQvawoDiN",
        "colab_type": "code",
        "outputId": "7405f659-6caf-40f6-974a-216a845d88b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if os.path.isfile(b'dataset/politicians/Afghanistan/Ashraf Ghani/annotations.csv'):\n",
        "    print('url list is inplace')\n",
        "else:\n",
        "    print('downloading the url list from the git')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "url list is inplace\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}