{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "info_box.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ratmcu/wiki_ner/blob/master/info_box.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C-w8h_nQnIm",
        "colab_type": "code",
        "outputId": "74cd8df6-950c-43dc-a0b7-e36490ebf169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "source": [
        "!pip install pyahocorasick\n",
        "!pip install fuzzyset\n",
        "from ahocorasick import Automaton\n",
        "import fuzzyset\n",
        "import urllib\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "import re\n",
        "import os\n",
        "import pandas as pd\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyahocorasick\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/9f/f0d8e8850e12829eea2e778f1c90e3c53a9a799b7f412082a5d21cd19ae1/pyahocorasick-1.4.0.tar.gz (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 4.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/90/61/87a55f5b459792fbb2b7ba6b31721b06ff5cf6bde541b40994\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: pyahocorasick\n",
            "Successfully installed pyahocorasick-1.4.0\n",
            "Collecting fuzzyset\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/78/7509f3efbb6acbcf842d7bdbd9a919ca8c0ed248123bdd8c57f08497e0dd/fuzzyset-0.0.19.tar.gz (377kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 5.0MB/s \n",
            "\u001b[?25hCollecting python-levenshtein (from fuzzyset)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/a9/d1785c85ebf9b7dfacd08938dd028209c34a0ea3b1bcdb895208bd40a67d/python-Levenshtein-0.12.0.tar.gz (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 22.9MB/s \n",
            "\u001b[?25hCollecting texttable (from fuzzyset)\n",
            "  Downloading https://files.pythonhosted.org/packages/04/c6/7d2514d76fefba65bfe2fa4e1082c3adea9edef5a149a3027b8f2d5ee0eb/texttable-1.6.1.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-levenshtein->fuzzyset) (41.0.1)\n",
            "Building wheels for collected packages: fuzzyset, python-levenshtein, texttable\n",
            "  Building wheel for fuzzyset (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/d8/36/9a/8f1cac047c7c3b03dce3d5434ed0088bfd8da8aeca615dfb4c\n",
            "  Building wheel for python-levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/c2/93/660fd5f7559049268ad2dc6d81c4e39e9e36518766eaf7e342\n",
            "  Building wheel for texttable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/4e/77/da46da4c5aece69b701cf45e6e4fe56ff98bfbdcc7b271d03b\n",
            "Successfully built fuzzyset python-levenshtein texttable\n",
            "Installing collected packages: python-levenshtein, texttable, fuzzyset\n",
            "Successfully installed fuzzyset-0.0.19 python-levenshtein-0.12.0 texttable-1.6.1\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no-derlySh-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PageContents():\n",
        "    def __init__(self, url):\n",
        "        self.quote_page = url\n",
        "        try:\n",
        "            self.page = urllib.request.urlopen(self.quote_page)\n",
        "            self.soup = BeautifulSoup(self.page, 'html.parser')\n",
        "        except:\n",
        "            self.table = False\n",
        "        try:\n",
        "            self.side_pane = self.soup.find('table', attrs={'class': 'infobox vcard'})\n",
        "            self.table_entry_list = self.side_pane.find('tbody').find_all('tr')\n",
        "            self.table = True\n",
        "        except:\n",
        "            self.table = False\n",
        "    #       print(self.table_entry_list)\n",
        "    #       self.table_entry_list = self.soup.find('tbody').find_all('tr')\n",
        "    \n",
        "    def get_party(self):\n",
        "#       side_pane = self.soup.find('table', attrs={'class': 'infobox vcard'})\n",
        "#       table_entry_list = side_pane.find_all('tr')\n",
        "        party = ''\n",
        "        for table_entry in self.table_entry_list:\n",
        "            for child in table_entry.children:\n",
        "                if child.text == 'Political party':\n",
        "                    party = child.next_sibling.contents[0].get('title')\n",
        "#                   print(party)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfb8Zq6EP6vR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InfoCard():\n",
        "    def __init__(self, page_content):\n",
        "        self.info_table = {}\n",
        "        if not page_content.table:\n",
        "            raise RuntimeError('page content is incomplete') from error\n",
        "        for table_entry in page_content.table_entry_list:\n",
        "            try:\n",
        "                row_left = table_entry.find('th', attrs={'scope': 'row'})\n",
        "                row_right = row_left.next_sibling\n",
        "                self.info_table[row_left.text] = self.get_text_parts(self.get_kids(row_right))\n",
        "            except:\n",
        "                pass\n",
        "        self.info_table = self.filter_info_scrapes(self.info_table)\n",
        "        print('info card is scraped successfully')\n",
        "        \n",
        "    def get_kids(self, html_mother):\n",
        "        kid_list = []\n",
        "        try:\n",
        "            kids = html_mother.children\n",
        "            for kid in kids:\n",
        "                kid_list.append(self.get_kids(kid))\n",
        "        except:\n",
        "            return html_mother\n",
        "        return kid_list \n",
        "\n",
        "    def get_text_parts(self, text_lists):\n",
        "        text_parts = []\n",
        "        if type(text_lists) == list:\n",
        "            for element in text_lists:\n",
        "                text_parts.extend(self.get_text_parts(element))\n",
        "        else:\n",
        "            text_parts.append(text_lists)\n",
        "        return(text_parts)\n",
        "\n",
        "    def filter_info_scrapes(self, scape_dict):\n",
        "        mask_dict = {}\n",
        "        for key, val in scape_dict.items():\n",
        "            mask_dict[key] = []\n",
        "            for i, element in enumerate(scape_dict[key]):\n",
        "                fnd = [c in element for c in u'()[]\\n\\xa0']\n",
        "                if not True in fnd:\n",
        "                    mask_dict[key].append(element)  \n",
        "        return mask_dict    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a5MnTqlglkE",
        "colab_type": "code",
        "outputId": "8d8bd041-48c7-4d6f-a3e7-ea99c6391096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        }
      },
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "import spacy\n",
        "import regex"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.0.18)\n",
            "Requirement already satisfied: thinc<6.13.0,>=6.12.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (6.12.1)\n",
            "Requirement already satisfied: regex==2018.01.10 in /usr/local/lib/python3.6/dist-packages (from spacy) (2018.1.10)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.16.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.21.0)\n",
            "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.35)\n",
            "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.9)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (4.28.1)\n",
            "Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.5.6)\n",
            "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.10.11)\n",
            "Requirement already satisfied: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.12.0)\n",
            "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.9.0.1)\n",
            "Requirement already satisfied: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.4.3.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy) (0.9.0)\n",
            "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en_core_web_sm\n",
            "\n",
            "    You can now load the model via spacy.load('en_core_web_sm')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbAQlKcZl1j2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# can we use snorkle to get this entity scraping done??? \n",
        "# if so it'd be better to have the lable functions in a ready way to generally working on all the pages!!\n",
        "# \n",
        "class PrivateEntities():\n",
        "    def __init__(self, info_card):\n",
        "        self.info_dict = info_card.info_table\n",
        "        self._get_entity_dict()\n",
        "        self._extract_entities()\n",
        "        \n",
        "    def _extract_entities(self):\n",
        "        # TREAT everyone the same? or call a seperate function per each entity?\n",
        "        # leave the not found entities as empty lists so we can use the html scraper to fill them\n",
        "        # lets treat everything generally, ultimate filtering happens at the comparison stage(if theres one)\n",
        "        for entity_key in self.entity_dict.keys():\n",
        "            self._pick_entity(self.entity_dict[entity_key], entity_key)\n",
        "            print(self.entity_dict[entity_key])\n",
        "    \n",
        "    def _pick_entity(self, entity_list, entity_key):\n",
        "        nlp = spacy.load(\"en_core_web_sm\")\n",
        "#         print(entity_list)\n",
        "        # Find named entities, phrases and concepts\n",
        "        entity_list.append([])\n",
        "#         print(entity_list[0][0])\n",
        "        \n",
        "        if entity_key == 'BIRTH_PLACE':\n",
        "            mask_str = ''\n",
        "            for scrape in self.info_dict[entity_list[0][0]]:\n",
        "                doc = nlp(str(scrape))\n",
        "                if doc.ents and doc.ents[0].label_ == 'DATE':\n",
        "                    mask_str = mask_str + 'd'\n",
        "                elif str(scrape) == ', ':\n",
        "                    mask_str = mask_str + 's'\n",
        "                elif self._is_name(str(scrape)):\n",
        "                    mask_str = mask_str + 't'\n",
        "                else:\n",
        "                    mask_str = mask_str + 'u'\n",
        "            print(mask_str)\n",
        "            indices = self._get_target_indices([r'[s][t]',r'[d][t]'], mask_str)  \n",
        "            for index in indices:\n",
        "                entity_list[1].append(self.info_dict[entity_list[0][0]][index])\n",
        "        else:    \n",
        "            for scrape in self.info_dict[entity_list[0][0]]:\n",
        "                doc = nlp(str(scrape))\n",
        "    #             print(scrape)\n",
        "                if doc.ents and doc.ents[0].label_ == entity_list[0][1]:\n",
        "                    entity_list[1].append(doc.ents[0].text)\n",
        "    #                 print(doc.ents[0].text)\n",
        "                elif not self._entity_noise(entity_key, str(scrape)):\n",
        "                    entity_list[1].append(str(scrape))\n",
        "                else:\n",
        "                    pass\n",
        "                \n",
        "    def _get_target_indices(self, pattern_list, mask_str):\n",
        "        '''TODO: if the target is inside the pattern'''\n",
        "        indices = []\n",
        "        for pattern in pattern_list:\n",
        "            m_iter = re.finditer(pattern, mask_str)\n",
        "            if m_iter:\n",
        "                for m in m_iter: \n",
        "                    indices.append(m.start()+1)\n",
        "        return indices        \n",
        "        \n",
        "    def _entity_noise(self, entity_key, text):\n",
        "        try:\n",
        "            return getattr(self, '_filter_{0}'.format(entity_key))(text)\n",
        "        except:\n",
        "            print('filter function for {0} not found'.format(entity_key))\n",
        "            return True\n",
        "    \n",
        "    def _get_entity_dict(self):\n",
        "        self.entity_dict = {}\n",
        "        if 'Born' in self.info_dict.keys():\n",
        "            self.entity_dict['NAME'] = [['Born', 'PERSON']]\n",
        "            self.entity_dict['BIRTH_DATE'] = [['Born', 'DATE']]\n",
        "            self.entity_dict['BIRTH_PLACE'] = [['Born', 'GPE']]\n",
        "        if 'Children' in self.info_dict.keys():\n",
        "            self.entity_dict['CHILDREN'] = [['Children', 'PERSON']]\n",
        "        if 'Spouse(s)' in self.info_dict.keys():\n",
        "            self.entity_dict['SPOUSES'] = [['Spouse(s)', 'PERSON']]\n",
        "        if 'Parents' in self.info_dict.keys():\n",
        "            self.entity_dict['PARENTS'] = [['Parents', 'PERSON']]\n",
        "        if 'Education' in self.info_dict.keys():\n",
        "            self.entity_dict['EDUCATION'] = [['Education', 'ORG']]\n",
        "    \n",
        "    def _filter_NAME(self, text):\n",
        "        '''cannot simply filter noise due to many possible candidates'''\n",
        "        return True\n",
        "    def _filter_BIRTH_DATE(self, text):\n",
        "        return True\n",
        "    def _filter_BIRTH_PLACE(self, text):\n",
        "        return True\n",
        "    def _filter_CHILDREN(self, text):\n",
        "#         return False # let's assume we don't find any noisy text under info boxes children till we do an analysis\n",
        "        return not self._is_name(text)\n",
        "    def _filter_SPOUSES(self, text):\n",
        "        return not self._is_name(text)\n",
        "    def _filter_PARENTS(self, text):\n",
        "        return not self._is_name(text)\n",
        "    def _filter_EDUCATION(self, text):\n",
        "        return True\n",
        "    def _is_name(self, text):\n",
        "        p = regex.compile(r\"\\p{Lu}\") # To support (currently) 1702 uppercase letters\n",
        "#         p = regex.compile(r\"[[:upper:]]\") # To support (currently) 1822 uppercase letters\n",
        "        if p.match(text):\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "        \n",
        "from unittest import TestCase\n",
        "\n",
        "class PrivateEntitiesTest(TestCase):\n",
        "    def setUp(self):\n",
        "        self.pvt_ent = PrivateEntities()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO4qpTb7vdMv",
        "colab_type": "code",
        "outputId": "8df308cb-07ac-4ac6-a45e-b549e0f25e0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "class example():\n",
        "    def __init__(self):\n",
        "        print('initialized')\n",
        "        getattr(self, 'chase_{0}'.format('clout'))('flacky')\n",
        "    def chase_clout(self, chaser):\n",
        "        print('chasing the clout with {0}'.format(chaser))\n",
        "\n",
        "ex = example()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initialized\n",
            "chasing the clout with flacky\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXrBEsRHxT_X",
        "colab_type": "code",
        "outputId": "d9b3b508-e880-493c-a4d9-65a366f202a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# pg = PageContents('https://en.wikipedia.org/wiki/Donald_Trump')\n",
        "# pg = PageContents('https://en.wikipedia.org/wiki/Barack_Obama')\n",
        "pg = PageContents('https://en.wikipedia.org/wiki/Joachim_Gauck')\n",
        "\n",
        "\n",
        "info_card = InfoCard(pg)\n",
        "# print(type(str(info_card.info_table['Born'][0])))\n",
        "pe = PrivateEntities(info_card)\n",
        "# pe.entity_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "info card is scraped successfully\n",
            "[['Born', 'PERSON'], []]\n",
            "[['Born', 'DATE'], ['1940-01-24', '24 January 1940']]\n",
            "ddtstst\n",
            "[['Born', 'GPE'], ['Mecklenburg', 'Nazi Germany', 'Rostock']]\n",
            "[['Children', 'PERSON'], []]\n",
            "[['Spouse(s)', 'PERSON'], ['Gerhild Radtke  ']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f84vuv5FxFH4",
        "colab_type": "code",
        "outputId": "f5ee9726-8faf-4ebc-e0a1-dd3b99f4472e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "info_card.info_table"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Born': ['1940-01-24',\n",
              "  '24 January 1940',\n",
              "  'Rostock',\n",
              "  ', ',\n",
              "  'Mecklenburg',\n",
              "  ', ',\n",
              "  'Nazi Germany'],\n",
              " 'Chancellor': ['Angela Merkel'],\n",
              " 'Children': ['4'],\n",
              " 'Constituency': ['Alliance 90 List'],\n",
              " 'Domestic partner': ['Daniela Schadt', ' '],\n",
              " 'Other politicalaffiliations': ['New Forum', '/', 'Alliance 90', ' '],\n",
              " 'Political party': ['Independent', ' '],\n",
              " 'Preceded by': ['Position established'],\n",
              " 'Signature': [],\n",
              " 'Spouse(s)': ['Gerhild Radtke  '],\n",
              " 'Succeeded by': ['Marianne Birthler']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aTBJEYOduK5",
        "colab_type": "code",
        "outputId": "322d0d91-8c2d-485e-bc56-9b11ea827035",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "entity_dict = {}\n",
        "entity_dict['NAME'] = [['Born', 'PERSON']]\n",
        "entity_dict['BIRTH_DATE'] = [['Born', 'DATE']]\n",
        "entity_dict['BIRTH_PLACE'] = [['Born', 'GPE']]\n",
        "entity_dict['CHILDREN'] = [['Children', 'PERSON']]\n",
        "entity_dict['SPOUSES'] = [['Spouse(s)', 'PERSON']]\n",
        "entity_dict['PARENTS'] = [['Born', 'PERSON']]\n",
        "entity_dict['EDUCATION'] = [['Education', 'ORG']]\n",
        "entity_dict.keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['NAME', 'BIRTH_DATE', 'BIRTH_PLACE', 'CHILDREN', 'SPOUSES', 'PARENTS', 'EDUCATION'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THHEwExcSNW2",
        "colab_type": "code",
        "outputId": "3f64a06b-9890-4a48-fa7c-f66c30809024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "pg = PageContents('https://en.wikipedia.org/wiki/Barack_Obama')\n",
        "# pg = PageContents('https://en.wikipedia.org/wiki/Donald_Trump')\n",
        "info_card = InfoCard(pg)\n",
        "info_card.info_table"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "info card is scraped successfully\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Awards': ['Nobel Peace Prize', '2009', 'Profile in Courage Award'],\n",
              " 'Born': ['Barack Hussein Obama II',\n",
              "  '1961-08-04',\n",
              "  'August 4, 1961',\n",
              "  'Honolulu',\n",
              "  ', ',\n",
              "  'Hawaii',\n",
              "  ', U.S.'],\n",
              " 'Children': ['Malia', 'Sasha'],\n",
              " 'Education': ['Occidental College',\n",
              "  'Columbia University',\n",
              "  'BA',\n",
              "  'Harvard University',\n",
              "  'JD'],\n",
              " 'Parents': ['Barack Obama Sr.', 'Ann Dunham'],\n",
              " 'Political party': ['Democratic'],\n",
              " 'Preceded by': ['Alice Palmer'],\n",
              " 'Relatives': ['Obama family'],\n",
              " 'Residence': [],\n",
              " 'Signature': [],\n",
              " 'Spouse(s)': ['Michelle Robinson', 'm.', '1992'],\n",
              " 'Succeeded by': ['Kwame Raoul'],\n",
              " 'Vice President': ['Joe Biden'],\n",
              " 'Website': ['Official website', 'Obama Foundation', 'White House Archives']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExO1B5tsc_Xv",
        "colab_type": "code",
        "outputId": "3d67420a-a546-40d9-b2f6-cab48c601d20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def get_kids(html_mother):\n",
        "    kid_list = []\n",
        "    try:\n",
        "        kids = html_mother.children\n",
        "        for kid in kids:\n",
        "            kid_list.append(get_kids(kid))\n",
        "    except:\n",
        "        return html_mother\n",
        "    return kid_list\n",
        "\n",
        "def get_text_parts(text_lists):\n",
        "    text_parts = []\n",
        "    if type(text_lists) == list:\n",
        "        for element in text_lists:\n",
        "            text_parts.extend(get_text_parts(element))\n",
        "    else:\n",
        "        text_parts.append(text_lists)\n",
        "    return(text_parts)\n",
        "\n",
        "def filter_info_scrapes(scape_dict):\n",
        "    mask_dict = {}\n",
        "    for key, val in scape_dict.items():\n",
        "#         print(key)\n",
        "#         print(scape_dict[key])\n",
        "        mask_dict[key] = []\n",
        "        for i, element in enumerate(scape_dict[key]):\n",
        "#             print(element)\n",
        "#             mask_dict[key].append(element)\n",
        "            fnd = [c in element for c in u'()[]\\n\\xa0']\n",
        "            if not True in fnd:\n",
        "#                 print('!!!')\n",
        "# #                 mask_dict[key][-1] = '1'\n",
        "# #                 del val[i]\n",
        "#             else:\n",
        "                mask_dict[key].append(element)  \n",
        "    return mask_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwG-k7UmTm3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pg = PageContents('https://en.wikipedia.org/wiki/Donald_Trump')\n",
        "# pg = PageContents('https://en.wikipedia.org/wiki/Ashraf_Ghani')\n",
        "# pg = PageContents('https://en.wikipedia.org/wiki/Oracle_Corporation')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n160QkjrSxaU",
        "colab_type": "code",
        "outputId": "1e93549c-2677-44a8-ccf6-b9d2da24d6e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "info_table = {}\n",
        "start = True\n",
        "\n",
        "for table_entry in pg.table_entry_list:\n",
        "#     for child in table_entry.children:\n",
        "    if table_entry.text == 'Personal details':\n",
        "        start = True\n",
        "    if start:    \n",
        "#             print(child.text)\n",
        "        try:\n",
        "            row_left = table_entry.find('th', attrs={'scope': 'row'})\n",
        "            row_right = row_left.next_sibling\n",
        "#             print(row_left.text)\n",
        "#             print(row_right)\n",
        "#             print(get_text_parts(get_kids(row_right)))\n",
        "            info_table[row_left.text] = get_text_parts(get_kids(row_right))\n",
        "#             break\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "# info_table\n",
        "# mthr\n",
        "info_table = filter_info_scrapes(info_table)\n",
        "# print(info_table)\n",
        "# info_table['Children'][0]\n",
        "info_table\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Awards': ['List of honors and awards'],\n",
              " 'Born': ['Donald John Trump',\n",
              "  '1946-06-14',\n",
              "  'June 14, 1946',\n",
              "  'Queens',\n",
              "  ', ',\n",
              "  'New York City'],\n",
              " 'Children': ['Donald Jr.', 'Ivanka', 'Eric', 'Tiffany', 'Barron'],\n",
              " 'Education': ['The Wharton School', 'BS', ' in ', 'Econ.'],\n",
              " 'Net worth': [],\n",
              " 'Occupation': ['Politician',\n",
              "  'businessman',\n",
              "  'real estate developer',\n",
              "  'television personality'],\n",
              " 'Other politicalaffiliations': ['Democratic', 'Reform', 'Independent'],\n",
              " 'Parents': ['Fred Trump', 'Mary Anne MacLeod'],\n",
              " 'Political party': ['Republican'],\n",
              " 'Preceded by': ['Barack Obama'],\n",
              " 'Relatives': ['Trump family'],\n",
              " 'Residence': ['White House', 'Trump Tower', 'Full list'],\n",
              " 'Signature': [],\n",
              " 'Spouse(s)': ['Ivana Zelníčková',\n",
              "  'm.',\n",
              "  '1977',\n",
              "  '; ',\n",
              "  'div.',\n",
              "  '1992',\n",
              "  'Marla Maples',\n",
              "  'm.',\n",
              "  '1993',\n",
              "  '; ',\n",
              "  'div.',\n",
              "  '1999',\n",
              "  'Melania Knauss',\n",
              "  'm.',\n",
              "  '2005'],\n",
              " 'Vice President': ['Mike Pence'],\n",
              " 'Website': ['Official website',\n",
              "  'White House website',\n",
              "  'Presidential Twitter',\n",
              "  'Personal Twitter']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKKNnYTHXrgl",
        "colab_type": "code",
        "outputId": "b8a7244e-d6fe-45dd-d352-45b255da2071",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1564
        }
      },
      "source": [
        "filter_info_scrapes(info_table)\n",
        "info_table"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Awards': ['List of honors and awards'],\n",
              " 'Born': ['Donald John Trump',\n",
              "  ' (',\n",
              "  '1946-06-14',\n",
              "  ') ',\n",
              "  'June 14, 1946',\n",
              "  ' (age\\xa072)',\n",
              "  'Queens',\n",
              "  ', ',\n",
              "  'New York City'],\n",
              " 'Children': ['\\n',\n",
              "  'Donald Jr.',\n",
              "  '\\n',\n",
              "  'Ivanka',\n",
              "  '\\n',\n",
              "  'Eric',\n",
              "  '\\n',\n",
              "  'Tiffany',\n",
              "  '\\n',\n",
              "  'Barron',\n",
              "  '\\n'],\n",
              " 'Education': ['The Wharton School', ' (', 'BS', ' in ', 'Econ.', ')'],\n",
              " 'Net worth': ['US$3.1\\xa0billion (March 2019)', '[a]'],\n",
              " 'Occupation': ['Politician',\n",
              "  'businessman',\n",
              "  'real estate developer',\n",
              "  'television personality'],\n",
              " 'Other politicalaffiliations': ['\\n',\n",
              "  'Democratic',\n",
              "  ' (until 1987, 2001–2009)',\n",
              "  '\\n',\n",
              "  'Reform',\n",
              "  ' (1999–2001)',\n",
              "  '\\n',\n",
              "  'Independent',\n",
              "  ' (2011–2012)',\n",
              "  '\\n'],\n",
              " 'Parents': ['Fred Trump', 'Mary Anne MacLeod'],\n",
              " 'Political party': ['Republican', ' (1987–1999, 2009–2011, 2012–present)'],\n",
              " 'Preceded by': ['Barack Obama'],\n",
              " 'Relatives': ['Trump family'],\n",
              " 'Residence': ['\\n',\n",
              "  'White House',\n",
              "  ' (official)',\n",
              "  '\\n',\n",
              "  'Trump Tower',\n",
              "  ' (personal)',\n",
              "  '\\n',\n",
              "  'Full list',\n",
              "  '\\n'],\n",
              " 'Signature': [],\n",
              " 'Spouse(s)': ['\\n',\n",
              "  'Ivana Zelníčková',\n",
              "  '(',\n",
              "  'm.',\n",
              "  '\\xa0',\n",
              "  '1977',\n",
              "  '; ',\n",
              "  'div.',\n",
              "  '\\xa0',\n",
              "  '1992',\n",
              "  ')',\n",
              "  '\\n',\n",
              "  'Marla Maples',\n",
              "  '(',\n",
              "  'm.',\n",
              "  '\\xa0',\n",
              "  '1993',\n",
              "  '; ',\n",
              "  'div.',\n",
              "  '\\xa0',\n",
              "  '1999',\n",
              "  ')',\n",
              "  '\\n',\n",
              "  'Melania Knauss',\n",
              "  ' (',\n",
              "  'm.',\n",
              "  '\\xa0',\n",
              "  '2005',\n",
              "  ')',\n",
              "  '\\n'],\n",
              " 'Vice President': ['Mike Pence'],\n",
              " 'Website': ['\\n',\n",
              "  'Official website',\n",
              "  '\\n',\n",
              "  'White House website',\n",
              "  '\\n',\n",
              "  'Presidential Twitter',\n",
              "  '\\n',\n",
              "  'Personal Twitter',\n",
              "  '\\n']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbcsjFhR5K54",
        "colab_type": "code",
        "outputId": "2a7f5d0f-c5ac-4d14-934c-dabc99175294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "[c in info_table['Spouse(s)'][-1] for c in u'()[],;.\\n']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[False, False, False, False, False, False, False, True]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}